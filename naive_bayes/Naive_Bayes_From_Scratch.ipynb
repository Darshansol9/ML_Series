{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for Gender Prediction Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given USA baby names, approx 250k female and male names<br>\n",
    "Now, given unknown name to us, predict whether it's a boy or a girl name\n",
    "\n",
    "Dataset:<br>\n",
    "<b>Taken from Back4App, use fake_application option and generate master-key and application-id</b><br>\n",
    "<b>Pull Data from their API as shown in the code</b><br>\n",
    "\n",
    "We will be using Naive Bayes to solve this problem. Enough though accuracy is not much great but from this notebook\n",
    "we can learn how to build Naive Classifier from scratch for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compare two values and who so ever is greater tag it as male or female and check the accuracy on test dataset\n",
    "\n",
    "P(Male | Name) = P(Name | Male)*P(Male) / P(Name)\n",
    "               = P(n|male) * P(a|Male) * P(m|Male) * P(e|Male) * P(Male)\n",
    "               = log(P(n|male)) + log(P(a|Male)).....+log(P(Male))\n",
    "        \n",
    "P(Female | Name) = Same fashion calculation\n",
    "\n",
    "As P(Name) will be coming for both male and female class, we don't cal at all. It acts as a normalizer\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://parseapi.back4app.com/classes/Complete_List_Names?count=1&limit=250000'\n",
    "headers = {\n",
    "    'X-Parse-Application-Id': 'paste your hascode api key', # This is the fake app's application id\n",
    "    'X-Parse-Master-Key': 'paste your hashcode master-key' # This is the fake app's readonly master key\n",
    "}\n",
    "data = json.loads(requests.get(url, headers=headers).content.decode('utf-8')) # Here you have the data that you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dict to pandas\n",
    "df = pd.DataFrame.from_dict(data['results'])\n",
    "\n",
    "#all lowercase conversion\n",
    "df['Name'] = df['Name'].apply(lambda x: x.lower())\n",
    "\n",
    "#dropping duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#filtering required columns\n",
    "df_final = df[['Name','Gender']]\n",
    "\n",
    "#shuffling data\n",
    "df_final = df_final.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#splitting into train and test\n",
    "test_ratio = 0.3\n",
    "train_idx = int(test_ratio * len(df_final))\n",
    "df_train,df_test = df_final.iloc[:train_idx],df_final.iloc[train_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "- In our case we are generating the distribution of each character for both male and female class\n",
    "- This will help in knowing which characters are seen more freq in male / female names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#responsible for storing character count for each male and female class, 0:female, 1:male\n",
    "dict_mapper = {0:defaultdict(int),1:defaultdict(int)}\n",
    "\n",
    "def letter_count(string,pos):\n",
    "    for i in string:\n",
    "        dict_mapper[pos][i] +=1\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    string = df_train.iloc[i]['Name']\n",
    "    gender = df_train.iloc[i]['Gender']\n",
    "    letter_count(string.lower(),1 if gender == 'male' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priors Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priors_cal(df_final):\n",
    "    \n",
    "    mf_data = df_final['Gender'].value_counts()\n",
    "    p_male = mf_data['male'] / len(df_final)\n",
    "    p_female = mf_data['female'] / len(df_final)\n",
    "    \n",
    "    return p_male,p_female,mf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.34914285714287"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def output_probs(name,letter_count,pos,prob):\n",
    "    \n",
    "    sum_prob = prob\n",
    "    '''\n",
    "    reason for adding 1 is called Laplace smoothing if we do not see the character in male or female class then\n",
    "    prob will be 0 and log(0) will raise an error\n",
    "    \n",
    "    This is unlikely to happen in character counts but think about spam filtering case where test words are not present \n",
    "    training dataset\n",
    "    '''\n",
    "    for i in name.lower():\n",
    "        sum_prob += math.log(dict_mapper[pos][i] + 1 / (letter_count+26))\n",
    "    \n",
    "    \n",
    "    return sum_prob\n",
    "\n",
    "\n",
    "def accuracy(female_letter_count,male_letter_count,p_male,p_female,df_test):\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(df_test)):\n",
    "        string = df_final.iloc[i]['Name'].lower()\n",
    "        gender = df_final.iloc[i]['Gender']\n",
    "        \n",
    "        p_name_female = output_probs(string,female_letter_count,0,p_female)\n",
    "        p_name_male = output_probs(string,male_letter_count,1,p_male)\n",
    "\n",
    "        if(p_name_male > p_name_female):\n",
    "            \n",
    "            if(gender == 'male'):\n",
    "                correct +=1\n",
    "        \n",
    "        else:\n",
    "            if(gender == 'female'):\n",
    "                correct +=1\n",
    "                \n",
    "        \n",
    "    return correct / len(df_test) * 100\n",
    "\n",
    "\n",
    "p_male,p_female,mf_data = priors_cal(df_train)\n",
    "female_letter_count,male_letter_count = sum(list(dict_mapper[0].values())),sum(list(dict_mapper[1].values()))\n",
    "\n",
    "\n",
    "#Using test dataset to check the accuracy of our model\n",
    "accuracy(female_letter_count,male_letter_count,p_male,p_female,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements Thoughts\n",
    "You can see, the accuracy is not so great<br>\n",
    "Can you think of different features to solve this problem?<br>\n",
    "For instance instead of counting each character, can we calculate the pair count ? 'Darshan' --> (d,a), (a,r) ...\n",
    "and apply the same logic. This is called 2-gram technique, where we are generating pairs of length 2 and solving the problem<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
